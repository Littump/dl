# Бинарная классификация для одобрения кредитов

Этот репозиторий содержит эксперименты по бинарной классификации для прогнозирования одобрения кредитов с использованием глубоких нейронных сетей.

## Набор данных

Набор данных взят из соревнования Kaggle: https://www.kaggle.com/competitions/playground-series-s4e10/overview

Он содержит характеристики заявителей на получение кредита, и задача состоит в том, чтобы предсказать, следует ли одобрить кредит или нет (бинарная классификация).

## Структура

Репозиторий организован следующим образом:

- `lib/`: Общая библиотека, используемая во всех экспериментах
  - `data.py`: Утилиты для загрузки и предобработки данных
  - `models.py`: Архитектуры моделей
  - `train.py`: Функции обучения и оценки
  - `utils.py`: Вспомогательные функции

- `experiment1/`: Эксперимент с простой моделью
- `experiment2/`: Эксперимент с более крупной моделью
- `experiment3/`: Эксперимент со skip-соединениями и batch-нормализацией
- `experiment4/`: Эксперимент с dropout
- `experiment5/`: Эксперимент с весовой регуляризацией и скоростью обучения

Каждый каталог эксперимента содержит:
- `train.py`: Скрипт обучения для эксперимента
- `plots/`: Каталог с графиками обучения
- `README.md`: Сводка результатов эксперимента

## Результаты экспериментов

### Эксперимент 1: Простая модель
- **Архитектура**: Простая нейронная сеть с 1 блоком, hidden_size=32, активация Sigmoid
- **Метрики**: Train AUC: 0.9236, Test AUC: 0.9286, Train Loss: 0.1998, Test Loss: 0.1922
- **Наблюдения**: Модель показала стабильное улучшение с каждой эпохой, достигнув хороших результатов даже с простой архитектурой.

### Эксперимент 2: Более крупная модель
- **Архитектура**: Расширенная сеть с 3 блоками, hidden_size=128, активация Sigmoid
- **Метрики**: Train AUC: 0.9304, Test AUC: 0.9329, Train Loss: 0.1806, Test Loss: 0.1920
- **Наблюдения**: Увеличение сложности модели привело к улучшению метрик. Большая емкость модели позволила лучше улавливать сложные паттерны в данных.

### Эксперимент 3: Skip-соединения и Batch-нормализация
- **Архитектура**: 3 блока с skip-соединениями и batch-нормализацией, hidden_size=128
- **Метрики**: Train AUC: 0.9274, Test AUC: 0.9298, Train Loss: 0.1913, Test Loss: 0.1814
- **Наблюдения**: Добавление skip-соединений и batch-нормализации повысило стабильность обучения. Наилучшие результаты были достигнуты на 4-й эпохе, что говорит о более быстрой сходимости.

### Эксперимент 4: Dropout
- **Архитектура**: 3 блока со skip-соединениями, batch-нормализацией и dropout
- **Метрики**: Train AUC: 0.9277, Test AUC: 0.9305, Train Loss: 0.1894, Test Loss: 0.1816
- **Наблюдения**: Оптимальное значение dropout (p=0.01) помогло немного улучшить обобщающую способность модели. Лучшие результаты были достигнуты на 6-й эпохе.

### Эксперимент 5: Весовая регуляризация и скорость обучения
- **Архитектура**: Архитектура эксперимента 4 с оптимизацией гиперпараметров
- **Метрики**: Train AUC: 0.9242, Test AUC: 0.9319, Train Loss: 0.1940, Test Loss: 0.1814
- **Наблюдения**: Оптимальные значения весовой регуляризации (weight_decay=0.001) и скорости обучения (learning_rate=0.1) обеспечили хороший баланс между обучением и обобщением.

## Ответы на вопросы

### 1. Какая архитектура нейронной сети показала наилучший результат?
Архитектура из эксперимента 2 показала наилучший результат по метрике Test AUC (0.9329), в то время как эксперименты 3, 4 и 5 показали лучший Test Loss (0.1814-0.1816). Учитывая компромисс между сложностью и производительностью, модель из эксперимента 5 с weight_decay=0.001 и learning_rate=0.1 может считаться оптимальной.

### 2. Какие методы регуляризации были применены, и как они повлияли на результаты?
Были применены следующие методы регуляризации:
- Batch-нормализация в экспериментах 3, 4 и 5 - улучшила стабильность обучения и ускорила сходимость
- Dropout (p=0.01) в эксперименте 4 - незначительно улучшил Test AUC с 0.9298 до 0.9305
- Weight decay (0.001) в эксперименте 5 - обеспечил хороший баланс между обучением и обобщением
Все методы регуляризации вместе помогли уменьшить переобучение и снизить Test Loss.

### 3. Как влияет размер скрытых слоев на производительность модели?
Увеличение размера скрытых слоев с 32 (эксперимент 1) до 128 (эксперимент 2) привело к улучшению Test AUC с 0.9286 до 0.9329 и Train AUC с 0.9236 до 0.9304. Большая емкость модели позволила лучше улавливать сложные зависимости в данных, но привела к небольшому увеличению Test Loss (с 0.1922 до 0.1920).

### 4. Какое влияние оказывают skip-соединения на обучение нейронной сети?
Skip-соединения, добавленные в эксперименте 3 вместе с batch-нормализацией, значительно улучшили Test Loss (с 0.1920 до 0.1814), несмотря на небольшое снижение Test AUC (с 0.9329 до 0.9298). Они обеспечивают лучшее распространение градиентов через сеть, что делает обучение более стабильным и ускоряет сходимость (лучшие результаты достигнуты на 4-й эпохе вместо 10-й).

### 5. Какие оптимальные значения гиперпараметров были найдены?
Оптимальные значения гиперпараметров:
- Размер скрытых слоев: 128
- Количество блоков: 3
- Dropout: 0.01 (эксперимент 4) или 0.2 (эксперимент 5)
- Weight decay: 0.001
- Learning rate: 0.1
- Batch-нормализация: включена
- Skip-соединения: включены

## Запуск экспериментов

Для запуска эксперимента:

```bash
cd experiment1
python train.py
```

## Требования

- PyTorch
- NumPy
- Matplotlib
- scikit-learn
- pandas
- tqdm

Подробнее см. requirements.txt